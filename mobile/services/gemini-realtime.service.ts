import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import AudioAnalyser from './audio-analyser.service';

/**
 * Gemini Realtime Service - Backend Proxy Approach
 * 
 * Implementa chat vocale audio-to-audio a bassa latenza usando
 * Gemini-2.5-Flash-Native-Audio tramite backend proxy WebSocket
 * con supporto per lingua italiana
 */

export interface GeminiRealtimeOptions {
  backendUrl?: string;
  language?: string;
  voiceName?: string;
  onSpeechStarted?: () => void;
  onSpeechStopped?: () => void;
  onAudioChunk?: (chunk: string) => void;
  onTextChunk?: (chunk: string) => void;
  onResponseDone?: () => void;
  onError?: (error: Error) => void;
  onAudioLevelUpdate?: (levels: { input: number; output: number; bass: number; mid: number; treble: number }) => void;
}

export class GeminiRealtimeService {
  private static instance: GeminiRealtimeService | null = null;
  private ws: WebSocket | null = null;
  private isConnected = false;
  private isRecording = false;
  private audioAnalyser: AudioAnalyser;
  private options: GeminiRealtimeOptions | null = null;
  private recording: Audio.Recording | null = null;

  private constructor() {
    this.audioAnalyser = new AudioAnalyser();
  }

  public static getInstance(): GeminiRealtimeService {
    if (!GeminiRealtimeService.instance) {
      GeminiRealtimeService.instance = new GeminiRealtimeService();
    }
    return GeminiRealtimeService.instance;
  }

  public async connect(options: GeminiRealtimeOptions): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        console.log('[Gemini Realtime] üîå Connecting to backend proxy...');
        
        this.options = options;
        const { backendUrl = 'ws://10.163.94.238:8080' } = options;

        // Connetti al backend proxy WebSocket
        this.ws = new WebSocket(backendUrl);
        
        this.ws.onopen = () => {
          console.log('[Gemini Realtime] ‚úÖ Connected to backend proxy');
          this.isConnected = true;
          
          // ‚úÖ Configura AudioAnalyser DOPO la connessione
          this.audioAnalyser.setOnAudioLevelUpdate((levels) => {
            if (this.options?.onAudioLevelUpdate) {
              this.options.onAudioLevelUpdate(levels);
            }
          });
          
          // ‚úÖ Risolvi la Promise quando il WebSocket √® connesso
          resolve();
        };
        
        this.ws.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            console.log('[Gemini Realtime] üì® Received:', data.type);
            
            switch (data.type) {
              case 'connected':
                console.log('[Gemini Realtime] ‚úÖ Backend connection confirmed');
                break;
              
              case 'audio':
                // ‚úÖ Gemini Live Audio chunk
                console.log('[Gemini Realtime] üéµ Audio chunk received from Gemini');
                this.playAudioChunk(data.audioData, data.mimeType);
                if (this.options?.onAudioChunk) {
                  this.options.onAudioChunk(data.audioData);
                }
                break;
              
              case 'text':
                // ‚úÖ Testo da Gemini
                console.log('[Gemini Realtime] üìù Text:', data.text);
                if (this.options?.onTextChunk) {
                  this.options.onTextChunk(data.text);
                }
                break;
              
              case 'interrupted':
                // ‚úÖ AI interrotto da user speech
                console.log('[Gemini Realtime] üõë AI interrupted');
                this.stopAllAudio();
                if (this.options?.onSpeechStarted) {
                  this.options.onSpeechStarted();
                }
                break;
              
              case 'response_complete':
                // ‚úÖ Risposta completa
                console.log('[Gemini Realtime] ‚úÖ Response complete');
                if (this.options?.onResponseDone) {
                  this.options.onResponseDone();
                }
                break;
                
              case 'error':
                console.error('[Gemini Realtime] ‚ùå Backend error:', data.message);
                if (this.options?.onError) {
                  this.options.onError(new Error(data.message));
                }
                break;
            }
          } catch (error) {
            console.error('[Gemini Realtime] ‚ùå Error parsing message:', error);
          }
        };
        
        this.ws.onerror = (error) => {
          console.error('[Gemini Realtime] ‚ùå WebSocket error:', error);
          this.isConnected = false;
          if (this.options?.onError) {
            this.options.onError(error as Error);
          }
          // ‚úÖ Rifiuta la Promise in caso di errore
          reject(error);
        };
        
        this.ws.onclose = () => {
          console.log('[Gemini Realtime] üîå WebSocket closed');
          this.isConnected = false;
        };

        console.log('[Gemini Realtime] ‚è≥ Waiting for WebSocket connection...');

      } catch (error) {
        console.error('[Gemini Realtime] ‚ùå Connection failed:', error);
        if (this.options?.onError) {
          this.options.onError(error as Error);
        }
        reject(error);
      }
    });
  }

  public async startAudioRecording(): Promise<void> {
    try {
      console.log('[Gemini Realtime] üé§ Starting continuous audio recording...');
      
      if (!this.isConnected || !this.ws) {
        throw new Error('Not connected to backend');
      }

      // ‚úÖ Se gi√† in registrazione, non fare nulla
      if (this.isRecording) {
        console.log('[Gemini Realtime] ‚ö†Ô∏è Already recording, skipping...');
        return;
      }

      // Richiedi permessi audio
      await Audio.requestPermissionsAsync();
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      // ‚úÖ Avvia registrazione continua (come audio-orb)
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      
      this.recording = recording;
      this.isRecording = true;
      
      // ‚úÖ Avvia invio automatico di chunk audio ogni 100ms
      this.startContinuousAudioSending();
      
      // Avvia l'analisi audio per visualizzazioni
      await this.audioAnalyser.startAnalysis();
      
      console.log('[Gemini Realtime] ‚úÖ Continuous audio recording started');

    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Failed to start recording:', error);
      throw error;
    }
  }

  private startContinuousAudioSending(): void {
    console.log('[Gemini Realtime] üîÑ Starting continuous audio sending...');
    
    // ‚úÖ Invia audio chunks ogni 2 secondi (registrazione reale)
    const interval = setInterval(async () => {
      if (!this.isRecording || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
        clearInterval(interval);
        return;
      }

      try {
        // ‚úÖ Crea una nuova registrazione temporanea per catturare audio
        const { recording } = await Audio.Recording.createAsync(
          Audio.RecordingOptionsPresets.HIGH_QUALITY
        );
        
        // ‚úÖ Registra per 1 secondo
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        // ‚úÖ Ferma e ottieni l'audio
        await recording.stopAndUnloadAsync();
        const uri = recording.getURI();
        
        if (uri) {
          // ‚úÖ Leggi il file audio
          const audioBase64 = await FileSystem.readAsStringAsync(uri, {
            encoding: FileSystem.EncodingType.Base64,
          });
          
          // ‚úÖ Invia al backend
          this.ws.send(JSON.stringify({
            type: 'audio',
            audioData: audioBase64,
            mimeType: 'audio/wav'
          }));
          
          console.log('[Gemini Realtime] üì§ Sent real audio chunk to backend');
        }

      } catch (error) {
        console.error('[Gemini Realtime] ‚ùå Error sending audio chunk:', error);
      }
    }, 2000); // Ogni 2 secondi

    // ‚úÖ Salva l'interval per cleanup
    (this as any).audioInterval = interval;
  }

  public async stopAudioRecording(): Promise<void> {
    try {
      console.log('[Gemini Realtime] üõë Stopping continuous audio recording...');
      
      if (!this.isRecording) {
        console.warn('[Gemini Realtime] ‚ö†Ô∏è No recording to stop');
        return;
      }
      
      // ‚úÖ Ferma l'invio continuo di chunk
      if ((this as any).audioInterval) {
        clearInterval((this as any).audioInterval);
        (this as any).audioInterval = null;
        console.log('[Gemini Realtime] üîÑ Stopped continuous audio sending');
      }
      
      // ‚úÖ Ferma la registrazione
      if (this.recording) {
        await this.recording.stopAndUnloadAsync();
        this.recording = null;
      }
      
      // ‚úÖ Ferma l'analisi audio
      await this.audioAnalyser.stopAnalysis();
      
      this.isRecording = false;
      
      console.log('[Gemini Realtime] ‚úÖ Continuous audio recording stopped');

    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Failed to stop recording:', error);
      throw error;
    }
  }

  public sendTextMessage(text: string): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.warn('[Gemini Realtime] ‚ö†Ô∏è WebSocket not connected, cannot send text');
      return;
    }
    
    try {
      this.ws.send(JSON.stringify({
        type: 'text',
        text: text
      }));
      console.log('[Gemini Realtime] üì§ Text sent to backend:', text);
    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Error sending text:', error);
    }
  }

  private audioQueue: Audio.Sound[] = [];
  private isPlayingAudio = false;

  private async playAudioChunk(audioBase64: string, mimeType: string): Promise<void> {
    try {
      console.log('[Gemini Realtime] üîä Playing audio chunk...');
      
      // ‚úÖ Crea URI data per audio PCM da Gemini
      const dataUri = `data:${mimeType};base64,${audioBase64}`;
      
      // ‚úÖ Carica audio chunk
      const { sound } = await Audio.Sound.createAsync(
        { uri: dataUri },
        { shouldPlay: !this.isPlayingAudio } // Play immediately se non c'√® nulla in riproduzione
      );

      this.audioQueue.push(sound);

      // ‚úÖ Gestisci queue
      if (!this.isPlayingAudio) {
        this.isPlayingAudio = true;
        this.playNextInQueue();
      }

      console.log('[Gemini Realtime] üéµ Audio chunk loaded, queue size:', this.audioQueue.length);

    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Error playing audio chunk:', error);
    }
  }

  private async playNextInQueue(): Promise<void> {
    if (this.audioQueue.length === 0) {
      this.isPlayingAudio = false;
      console.log('[Gemini Realtime] ‚úÖ Audio queue empty');
      return;
    }

    const sound = this.audioQueue.shift();
    if (!sound) return;

    try {
      // ‚úÖ Configura callback per riprodurre il prossimo chunk
      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          console.log('[Gemini Realtime] ‚úÖ Chunk finished, playing next...');
          sound.unloadAsync();
          this.playNextInQueue(); // ‚úÖ Riproduce il prossimo
        }
      });

      // ‚úÖ Avvia riproduzione se non gi√† in corso
      const status = await sound.getStatusAsync();
      if (status.isLoaded && !status.isPlaying) {
        await sound.playAsync();
      }

    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Error in queue playback:', error);
      this.playNextInQueue(); // Continua con il prossimo
    }
  }

  private async stopAllAudio(): Promise<void> {
    console.log('[Gemini Realtime] üõë Stopping all audio...');
    
    // ‚úÖ Ferma tutti i chunk in coda
    for (const sound of this.audioQueue) {
      try {
        await sound.stopAsync();
        await sound.unloadAsync();
      } catch (error) {
        console.error('[Gemini Realtime] ‚ùå Error stopping audio:', error);
      }
    }
    
    this.audioQueue = [];
    this.isPlayingAudio = false;
    
    console.log('[Gemini Realtime] ‚úÖ All audio stopped');
  }

  public disconnect(): void {
    try {
      console.log('[Gemini Realtime] üîå Disconnecting...');
      
      if (this.isRecording) {
        this.stopAudioRecording();
      }
      
      if (this.ws) {
        this.ws.close();
        this.ws = null;
      }
      
      if (this.audioAnalyser) {
        this.audioAnalyser.destroy();
      }
      
      this.isConnected = false;
      this.options = null;
      
      console.log('[Gemini Realtime] ‚úÖ Disconnected successfully');

    } catch (error) {
      console.error('[Gemini Realtime] ‚ùå Error during disconnect:', error);
    }
  }

  public getConnectionStatus(): boolean {
    return this.isConnected && this.ws?.readyState === WebSocket.OPEN;
  }

  public getRecordingStatus(): boolean {
    return this.isRecording;
  }
}

export default GeminiRealtimeService;